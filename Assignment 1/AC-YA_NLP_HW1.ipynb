{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence reformulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download FastText pretrained vectors for English: \n",
    "[cc.en300.vec.gz](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz)\n",
    "\n",
    "And download Yelp! dataset composed of reviews: \n",
    "[Yelp.train.text](https://drive.google.com/file/d/1TAcfL091lKb2LipaUELFteZqJjQu-gMa/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz \n",
    "# !gunzip -k cc.en.300.vec.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load downloaded pretrained FastText vectors by gensim library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\"\n",
    "fast = KeyedVectors.load_word2vec_format('cc.en.300.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute similarity of two words using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The similiarity between the vectors for the words \"king\" and \"queen\" is 0.7069182991981506.\nThe distance between \"king\" and \"queen\" is 0.29308170080184937\n1.0\nThe similiarity between the vectors for the words \"king\" and \"man\" is 0.341844379901886.\nThe distance between \"king\" and \"man\" is 0.658155620098114\n1.0\nThe similiarity between the vectors for the words \"king\" and \"woman\" is 0.22299695014953613.\nThe distance between \"king\" and \"woman\" is 0.7770030498504639\n1.0\nThe similiarity between the vectors for the words \"queen\" and \"woman\" is 0.3607560992240906.\nThe distance between \"queen\" and \"woman\" is 0.6392439007759094\n1.0\nThe similiarity between the vectors for the words \"queen\" and \"man\" is 0.22957992553710938.\nThe distance between \"queen\" and \"man\" is 0.7704200744628906\n1.0\nThe similiarity between the vectors for the words \"woman\" and \"man\" is 0.7658364176750183.\nThe distance between \"woman\" and \"man\" is 0.2341635823249817\n1.0\n"
    }
   ],
   "source": [
    "#We discussed different words, look and similarity of 'king' and 'queen' for example. Could you put it inot context?\n",
    "\n",
    "#your code here\n",
    "print(f'The similiarity between the vectors for the words \"king\" and \"queen\" is {fast.similarity(\"king\", \"queen\")}.')\n",
    "print(f'The distance between \"king\" and \"queen\" is {fast.distance(\"king\", \"queen\")}')\n",
    "print(fast.distance(\"king\", \"queen\") + fast.similarity(\"king\", \"queen\"))\n",
    "print(f'The similiarity between the vectors for the words \"king\" and \"man\" is {fast.similarity(\"king\", \"man\")}.')\n",
    "print(f'The distance between \"king\" and \"man\" is {fast.distance(\"king\", \"man\")}')\n",
    "print(fast.distance(\"king\", \"man\") + fast.similarity(\"king\", \"man\"))\n",
    "print(f'The similiarity between the vectors for the words \"king\" and \"woman\" is {fast.similarity(\"king\", \"woman\")}.')\n",
    "print(f'The distance between \"king\" and \"woman\" is {fast.distance(\"king\", \"woman\")}')\n",
    "print(fast.distance(\"king\", \"woman\") + fast.similarity(\"king\", \"woman\"))\n",
    "print(f'The similiarity between the vectors for the words \"queen\" and \"woman\" is {fast.similarity(\"queen\", \"woman\")}.')\n",
    "print(f'The distance between \"queen\" and \"woman\" is {fast.distance(\"queen\", \"woman\")}')\n",
    "print(fast.distance(\"queen\", \"woman\") + fast.similarity(\"queen\", \"woman\"))\n",
    "print(f'The similiarity between the vectors for the words \"queen\" and \"man\" is {fast.similarity(\"queen\", \"man\")}.')\n",
    "print(f'The distance between \"queen\" and \"man\" is {fast.distance(\"queen\", \"man\")}')\n",
    "print(fast.distance(\"queen\", \"man\") + fast.similarity(\"queen\", \"man\"))\n",
    "print(f'The similiarity between the vectors for the words \"woman\" and \"man\" is {fast.similarity(\"woman\", \"man\")}.')\n",
    "print(f'The distance between \"woman\" and \"man\" is {fast.distance(\"woman\", \"man\")}')\n",
    "print(fast.distance(\"woman\", \"man\") + fast.similarity(\"woman\", \"man\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the similarity between the word vectors for \"queen\" and \"king\" is very high, approximately 70%.\n",
    "The distance between the words is approximately 0.29, and in fact the distance between any two words = (1 - similarity)\n",
    "\n",
    "We can also see that the distance between \"queen\"-\"woman\" is almost the same as the distance between \"king\"-\"man\", and the same holds for the distance between \"queen\"-\"man\" and \"king\"-\"woman\"., while the distance between \"man\"-\"woman\" is almost the same as \"queen\"-\"king\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence tokenization. Split Yelp! texts into separate tokens (words and punctuation marks) by space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "with open(\"Yelp.train.text\") as text:\n",
    "    yelp_data = text.read()\n",
    "    yelp_space_split = yelp_data.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try part of speech tagging using [NLTK POS-tagger](https://www.nltk.org/book/ch05.html).\n",
    "The function returns list of tuples (word, POS_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "yelp_tokens = nltk.word_tokenize(yelp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_yelp_space = nltk.pos_tag(yelp_space_split)\n",
    "# pos_yelp_tokens = nltk.pos_tag(yelp_tokens[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you find the most similar word to the given? Can you write a method that returns a list of tuples (word, similarity) in order of decreasing similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def find_most_similar(word, n=10):\n",
    "    results = fast.similar_by_word(word, topn=n)\n",
    "    return results  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the simplest reformulation task. We just want to reformulate some sentences replacing an ajective with a similar one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformulate_sentence(sentence):\n",
    "    # Sentence tokenization\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Part of speech tagging\n",
    "    POS_tagged_words = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "    reformulated_sentence_words = []\n",
    "    for word, pos_tag in POS_tagged_words:\n",
    "        # If the word is adjective...\n",
    "        if pos_tag in ['JJR', 'JJS', 'JJ']:\n",
    "            try:\n",
    "                # ...look for the word most similar to the given and replace it\n",
    "                # your code here\n",
    "                sim_words = find_most_similar(word, n=10)\n",
    "                print(sim_words)\n",
    "                for w in sim_words:\n",
    "                    if w[0].lower() in word.lower():\n",
    "                        continue\n",
    "                    else:\n",
    "                        word = w[0]\n",
    "                        break\n",
    "                reformulated_sentence_words.append(word)\n",
    "            except:\n",
    "                print(f'There is no {word} word in FastText dictionary! ...')\n",
    "        else:\n",
    "            reformulated_sentence_words.append(word)\n",
    "    # Join words list in a sentence\n",
    "    return ' '.join(reformulated_sentence_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/Adam/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER sentiment classifier from NLTK library. The range of sentiment is from -1 to 1 where -1 is negative, 0 is neutral and 1 is positive\n",
    "\n",
    "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset text file line by line and put lines into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "with open(\"Yelp.train.text\") as text:\n",
    "    yelp_lines = text.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Yelp dataset from text file and get 1000 random sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "yelp_sample = random.choices(yelp_lines, k=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute average sentiment of 1000 sentences sentences set by VADER sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n    "
     },
     "metadata": {}
    }
   ],
   "source": [
    "avg_sentiment = np.mean([sentiment_analyzer.polarity_scores(line)['compound'] for line in yelp_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformulate sentences and compute average sentiment again. Try to come up with ways to make senteces more positive on average. What about more negative? Can you come up with some interesting experiment on this data with POS-tagged reformulations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformulate_sentence_mode(sentence, mode ='pos'):\n",
    "    # Sentence tokenization\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Part of speech tagging\n",
    "    POS_tagged_words = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "    reformulated_sentence_words = []\n",
    "    for word, pos_tag in POS_tagged_words:\n",
    "        # If the word is adjective...\n",
    "        if pos_tag in ['JJR', 'JJS', 'JJ']:\n",
    "            try:\n",
    "                # ...look for the word most similar to the given and replace it\n",
    "                # your code here\n",
    "                sim_words = find_most_similar(word, n=10)\n",
    "                max_word = 0\n",
    "                for sim_word,sim in sim_words:\n",
    "                    if sim_word.lower() in word.lower():\n",
    "                        continue\n",
    "                    analyz = sentiment_analyzer.polarity_scores(sim_word)\n",
    "                    scores = sim * analyz['compound']\n",
    "                    if (mode == 'pos' and scores  > max_word) or (mode == 'neg' and scores  < max_word):\n",
    "                        max_word = scores \n",
    "                        word = sim_word\n",
    "                            \n",
    "                reformulated_sentence_words.append(word)\n",
    "            except:\n",
    "                print(f'There is no {word} word in FastText dictionary! ...')\n",
    "        else:\n",
    "            reformulated_sentence_words.append(word)\n",
    "    # Join words list in a sentence\n",
    "    return ' '.join(reformulated_sentence_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ROW :  i like happy dags\n{'neg': 0.0, 'neu': 0.139, 'pos': 0.861, 'compound': 0.7351}\nPositive :  i like happier dags\n{'neg': 0.0, 'neu': 0.145, 'pos': 0.855, 'compound': 0.7096}\nPositive :  i like unhappy dags\n{'neg': 0.444, 'neu': 0.159, 'pos': 0.397, 'compound': -0.0772}\n714.8599119186401\n"
    }
   ],
   "source": [
    "now = time.time()\n",
    "sentence = 'i like happy dags'\n",
    "print('ROW : ', sentence)\n",
    "print(sentiment_analyzer.polarity_scores(sentence))\n",
    "pos_sentence = reformulate_sentence_mode(sentence, mode='pos')\n",
    "print('Positive : ', pos_sentence)\n",
    "print(sentiment_analyzer.polarity_scores(pos_sentence))\n",
    "neg_sentence = reformulate_sentence_mode(sentence, mode='neg')\n",
    "print('Positive : ', neg_sentence)\n",
    "print(sentiment_analyzer.polarity_scores(neg_sentence))\n",
    "print(time.time() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_compound = 0\n",
    "avg = 0\n",
    "pos = 0\n",
    "neg = 0\n",
    "n = len(yelp_sample)\n",
    "for sentence in tqdm(yelp_sample):\n",
    "    avg += sentiment_analyzer.polarity_scores(sentence)['compound']\n",
    "    pos += sentiment_analyzer.polarity_scores(reformulate_sentence_mode(sentence, mode='pos'))['compound']\n",
    "    neg += sentiment_analyzer.polarity_scores(reformulate_sentence_mode(sentence,mode='neg'))['compound']\n",
    "avg/=n\n",
    "pos/=n\n",
    "neg/=n\n",
    "print('Pos : ',pos)\n",
    "print('Avg : ',avg)\n",
    "print('Neg : ',neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformulate_sentence_all_option(sentence, word_similar=0.7):\n",
    "    # Sentence tokenization\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "    # Part of speech tagging\n",
    "    POS_tagged_words = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "    reformulated_sentence_words = []\n",
    "    for word, pos_tag in POS_tagged_words:\n",
    "        # If the word is adjective...\n",
    "        words = []\n",
    "        words.append(word)\n",
    "        if pos_tag in ['JJR', 'JJS', 'JJ']:\n",
    "            try:\n",
    "                # ...look for the word most similar to the given and replace it\n",
    "                # your code here\n",
    "                sim_words = find_most_similar(word, n=10)\n",
    "                for sim_word,sim in sim_words:\n",
    "                    if sim >word_similar:\n",
    "                        words.append(sim_word)\n",
    "            except:\n",
    "                print(f'There is no {word} word in FastText dictionary! ...')\n",
    "        reformulated_sentence_words.append(words)\n",
    "\n",
    "    return reformulated_sentence_words\n",
    "\n",
    "def rate(x , i=0):\n",
    "    if len(x) == i:\n",
    "        return []\n",
    "    ret_s = []\n",
    "    ends = rate(x , i+1)\n",
    "    if len(ends) == 0 :\n",
    "        return x[i]\n",
    "    for word in x[i]:\n",
    "        for end in ends:\n",
    "            s = word +' ' + end\n",
    "            ret_s.append(s)\n",
    "    return ret_s\n",
    "\n",
    "def pos_neg_sentiment(sentence):\n",
    "    x = reformulate_sentence_all_option(sentence)\n",
    "    score = sentiment_analyzer.polarity_scores(sentence)['compound']\n",
    "    ret_dict = {'pos': (score,sentence) , 'neg':(score,sentence),'normal':(score,sentence)  }\n",
    "    for s in rate(x):\n",
    "        analyz = sentiment_analyzer.polarity_scores(s)['compound']\n",
    "        if (analyz > 0) and (ret_dict['pos'][0]<analyz):\n",
    "            ret_dict['pos'] = (analyz,s)\n",
    "        if (analyz < 0) and (ret_dict['neg'][0]>analyz):\n",
    "            ret_dict['neg'] = (analyz,s)\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_compound = 0\n",
    "avg = 0\n",
    "pos = 0\n",
    "neg = 0\n",
    "for sentence in tqdm(yelp_sample):\n",
    "    scores = pos_neg_sentiment(sentence)\n",
    "    avg += scores['normal'][0]\n",
    "    pos += scores['pos'][0]\n",
    "    neg += scores['neg'][0]\n",
    "avg/=(len(res))\n",
    "pos/=(len(res))\n",
    "neg/=(len(res))\n",
    "print('Pos : ',pos)\n",
    "print('Avg : ',avg)\n",
    "print('Neg : ',neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('yandex': virtualenv)",
   "language": "python",
   "name": "python37564bityandexvirtualenv9d32818e7464483c97cb7ec262d53e40"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}