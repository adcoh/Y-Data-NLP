{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lecture 5 transformers_multi-label_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVorkyBpzKAg",
        "colab_type": "text"
      },
      "source": [
        "# Fine Tuning Transformer for MultiLabel Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJnyJr6PzKAn",
        "colab_type": "text"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "In this tutorial we will be fine tuning a transformer model for the **Multilabel text classification** problem. \n",
        "This is one of the most common business problems where a given piece of text/sentence/document needs to be classified into one or more of categories out of the given list. For example a movie can be categorized into 1 or more genres.\n",
        "\n",
        "#### Flow of the notebook\n",
        "\n",
        "The notebook will be divided into seperate sections to provide a organized walk through for the process used. This process can be modified for individual use cases. The sections are:\n",
        "\n",
        "1. [Importing Python Libraries and preparing the environment](#section01)\n",
        "2. [Importing and Pre-Processing the domain data](#section02)\n",
        "3. [Preparing the Dataset and Dataloader](#section03)\n",
        "4. [Creating the Neural Network for Fine Tuning](#section04)\n",
        "5. [Fine Tuning the Model](#section05)\n",
        "6. [Validating the Model Performance](#section06)\n",
        "\n",
        "\n",
        "#### Data: \n",
        "\t We are using the Jigsaw toxic data from [Kaggle](https://www.kaggle.com/)\n",
        "     This is competion provide the souce dataset [Toxic Comment Competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
        "\t  We are referring only to the first csv file from the data dump: `train.csv`\n",
        "\t  There are rows of data.  Where each row has the following data-point: \n",
        "\t\t - Comment Text\n",
        "\t\t - `toxic`\n",
        "\t\t - `severe_toxic`\n",
        "\t\t - `obscene`\n",
        "\t\t - `threat`\n",
        "\t\t - `insult`\n",
        "\t\t - `identity_hate`\n",
        "\n",
        "Each comment can be marked for multiple categories. If the comment is `toxic` and `obscene`, then for both those headers the value will be `1` and for the others it will be `0`.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "***NOTE***\n",
        "- *It is to be noted that the overall mechanisms for a multiclass and multilabel problems are similar, except for few differences namely:*\n",
        "\t- *Loss function is designed to evaluate all the probability of categories individually rather than as compared to other categories. Hence the use of `BCE` rather than `Cross Entropy` when defining loss.*\n",
        "\t- *Sigmoid of the outputs calcuated to rather than Softmax. Again for the reasons defined in the previous point*\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2EjEeAPzKAr",
        "colab_type": "text"
      },
      "source": [
        "<a id='section01'></a>\n",
        "### Importing Python Libraries and preparing the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WD_vnyLXZQzD",
        "outputId": "faf757de-b6da-4712-ac4f-de0011309882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# Installing the transformers library and additional libraries if looking process \n",
        "\n",
        "!pip install -q transformers\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 20.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 34.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pzM1_ykHaFur",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Wn3LN7bwdI",
        "colab_type": "code",
        "outputId": "ce74cf47-1e8f-44a8-c7a6-2b1ddb2ed560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NLxxwd1scQNv",
        "outputId": "866cf865-22f4-40c0-a07a-96c2043ec50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHMpFig_zKBp",
        "colab_type": "text"
      },
      "source": [
        "<a id='section02'></a>\n",
        "### Importing and Pre-Processing the domain data\n",
        "\n",
        "We will be working with the data and preparing for fine tuning purposes. \n",
        "*Assuming that the `train.csv` is already downloaded, unzipped and saved in your `data` folder*\n",
        "\n",
        "* Import the file in a dataframe and give it the headers as per the documentation.\n",
        "* Taking the values of all the categories and coverting it into a list.\n",
        "* The list is appened as a new column and other columns are removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mZ7lTlkyaG7u",
        "outputId": "84b39e11-3278-4200-99cd-59aa367f4d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df = pd.read_csv('./drive/My Drive/data/class5/train.csv')\n",
        "df['list'] = df[df.columns[2:]].values.tolist()\n",
        "new_df = df[['comment_text', 'list']].copy()\n",
        "new_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text                list\n",
              "0  Explanation\\nWhy the edits made under my usern...  [0, 0, 0, 0, 0, 0]\n",
              "1  D'aww! He matches this background colour I'm s...  [0, 0, 0, 0, 0, 0]\n",
              "2  Hey man, I'm really not trying to edit war. It...  [0, 0, 0, 0, 0, 0]\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...  [0, 0, 0, 0, 0, 0]\n",
              "4  You, sir, are my hero. Any chance you remember...  [0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcUlgo66zKB8",
        "colab_type": "text"
      },
      "source": [
        "<a id='section03'></a>\n",
        "### Preparing the Dataset and Dataloader\n",
        "\n",
        "We will start with defining few key variables that will be used later during the training/fine tuning stage.\n",
        "Followed by creation of CustomDataset class - This defines how the text is pre-processed before sending it to the neural network. We will also define the Dataloader that will feed  the data in batches to the neural network for suitable training and processing. \n",
        "Dataset and Dataloader are constructs of the PyTorch library for defining and controlling the data pre-processing and its passage to neural network. For further reading into Dataset and Dataloader read the [docs at PyTorch](https://pytorch.org/docs/stable/data.html)\n",
        "\n",
        "#### *CustomDataset* Dataset Class\n",
        "- This class is defined to accept the `tokenizer`, `dataframe` and `max_length` as input and generate tokenized output and tags that is used by the BERT model for training. \n",
        "- We are using the BERT tokenizer to tokenize the data in the `comment_text` column of the dataframe.\n",
        "- The tokenizer uses the `encode_plus` method to perform tokenization and generate the necessary outputs, namely: `ids`, `attention_mask`, `token_type_ids`\n",
        "---\n",
        "- *This is the first difference between the distilbert and bert, where the tokenizer generates the token_type_ids in case of Bert*\n",
        "---\n",
        "- To read further into the tokenizer, [refer to this document](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer)\n",
        "- `targest` is the list of categories labled as `0` or `1` in the dataframe. \n",
        "- The *CustomDataset* class is used to create 2 datasets, for training and for validation.\n",
        "- *Training Dataset* is used to fine tune the model: **80% of the original data**\n",
        "- *Validation Dataset* is used to evaluate the performance of the model. The model has not seen this data during training. \n",
        "\n",
        "#### Dataloader\n",
        "- Dataloader is used to for creating training and validation dataloader that load data to the neural network in a defined manner. This is needed because all the data from the dataset cannot be loaded to the memory at once, hence the amount of dataloaded to the memory and then passed to the neural network needs to be controlled.\n",
        "- This control is achieved using the parameters such as `batch_size` and `max_len`.\n",
        "- Training and Validation dataloaders are used in the training and validation part of the flow respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ikfbFlNHgi8T",
        "colab": {}
      },
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 100\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oFOylAXqiNYK",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.comment_text = dataframe.comment_text\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "         \n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PkDGqarcPowL",
        "outputId": "58edaafb-611d-41f8-f93f-666cce429c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=new_df.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (159571, 2)\n",
            "TRAIN Dataset: (127657, 2)\n",
            "TEST Dataset: (31914, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlXR6fIHf-UV",
        "colab_type": "code",
        "outputId": "cbf68409-6271-428d-8629-c429aa74836e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        }
      },
      "source": [
        "training_set[10005]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': tensor([  101, 10166, 14719,  2615,  2003,  8915,  2232,  4047,  2023,  6643,\n",
              "         13910,   999,   999,   999,  8840,  2140,  1010,  2798,  1013, 14719,\n",
              "          2615,  3849,  2000,  2022,  1037,  2613,  6904,  2290,  1012,  8239,\n",
              "          4632,  9148,  5051,   102,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'targets': tensor([1., 0., 1., 0., 0., 0.]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLpilV73QrXJ",
        "colab": {}
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jcTkWKzKC2",
        "colab_type": "text"
      },
      "source": [
        "<a id='section04'></a>\n",
        "### Creating the Neural Network for Fine Tuning\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DegHNyIEQxB2",
        "outputId": "34a5e146-4de9-4260-8c0b-def628d7ae2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 6)\n",
        "        \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1= self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7KnNeQx6SI78",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gUD8j0c7WsA-",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGf7RssVzKDW",
        "colab_type": "text"
      },
      "source": [
        "<a id='section05'></a>\n",
        "### Fine Tuning the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B9_DjWmfWx1q",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    epoch_step = 0\n",
        "    for data in tqdm(training_loader):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        if epoch_step%100==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_step+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4Yl7gXHYSRU",
        "outputId": "4f8d136b-18b0-4d0d-afdb-a3eb0116c241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/7979 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/7979 [00:00<29:37,  4.49it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.6522731781005859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 2/7979 [00:00<29:55,  4.44it/s]\u001b[A\n",
            "  0%|          | 3/7979 [00:00<28:24,  4.68it/s]\u001b[A\n",
            "  0%|          | 4/7979 [00:00<27:41,  4.80it/s]\u001b[A\n",
            "  0%|          | 5/7979 [00:01<27:00,  4.92it/s]\u001b[A\n",
            "  0%|          | 6/7979 [00:01<26:47,  4.96it/s]\u001b[A\n",
            "  0%|          | 7/7979 [00:01<26:21,  5.04it/s]\u001b[A\n",
            "  0%|          | 8/7979 [00:01<26:28,  5.02it/s]\u001b[A\n",
            "  0%|          | 9/7979 [00:01<26:26,  5.02it/s]\u001b[A\n",
            "  0%|          | 10/7979 [00:02<26:04,  5.09it/s]\u001b[A\n",
            "  0%|          | 11/7979 [00:02<26:36,  4.99it/s]\u001b[A\n",
            "  0%|          | 12/7979 [00:02<26:33,  5.00it/s]\u001b[A\n",
            "  0%|          | 13/7979 [00:02<26:24,  5.03it/s]\u001b[A\n",
            "  0%|          | 14/7979 [00:02<25:57,  5.11it/s]\u001b[A\n",
            "  0%|          | 15/7979 [00:02<25:49,  5.14it/s]\u001b[A\n",
            "  0%|          | 16/7979 [00:03<25:37,  5.18it/s]\u001b[A\n",
            "  0%|          | 17/7979 [00:03<25:53,  5.12it/s]\u001b[A\n",
            "  0%|          | 18/7979 [00:03<25:52,  5.13it/s]\u001b[A\n",
            "  0%|          | 19/7979 [00:03<26:16,  5.05it/s]\u001b[A\n",
            "  0%|          | 20/7979 [00:03<26:08,  5.08it/s]\u001b[A\n",
            "  0%|          | 21/7979 [00:04<25:37,  5.18it/s]\u001b[A\n",
            "  0%|          | 22/7979 [00:04<25:39,  5.17it/s]\u001b[A\n",
            "  0%|          | 23/7979 [00:04<25:42,  5.16it/s]\u001b[A\n",
            "  0%|          | 24/7979 [00:04<26:28,  5.01it/s]\u001b[A\n",
            "  0%|          | 25/7979 [00:04<26:12,  5.06it/s]\u001b[A\n",
            "  0%|          | 26/7979 [00:05<26:16,  5.05it/s]\u001b[A\n",
            "  0%|          | 27/7979 [00:05<26:08,  5.07it/s]\u001b[A\n",
            "  0%|          | 28/7979 [00:05<26:07,  5.07it/s]\u001b[A\n",
            "  0%|          | 29/7979 [00:05<26:03,  5.09it/s]\u001b[A\n",
            "  0%|          | 30/7979 [00:05<25:58,  5.10it/s]\u001b[A\n",
            "  0%|          | 31/7979 [00:06<26:12,  5.05it/s]\u001b[A\n",
            "  0%|          | 32/7979 [00:06<26:29,  5.00it/s]\u001b[A\n",
            "  0%|          | 33/7979 [00:06<26:01,  5.09it/s]\u001b[A\n",
            "  0%|          | 34/7979 [00:06<25:51,  5.12it/s]\u001b[A\n",
            "  0%|          | 35/7979 [00:06<25:57,  5.10it/s]\u001b[A\n",
            "  0%|          | 36/7979 [00:07<26:22,  5.02it/s]\u001b[A\n",
            "  0%|          | 37/7979 [00:07<25:53,  5.11it/s]\u001b[A\n",
            "  0%|          | 38/7979 [00:07<26:28,  5.00it/s]\u001b[A\n",
            "  0%|          | 39/7979 [00:07<26:15,  5.04it/s]\u001b[A\n",
            "  1%|          | 40/7979 [00:07<26:17,  5.03it/s]\u001b[A\n",
            "  1%|          | 41/7979 [00:08<25:50,  5.12it/s]\u001b[A\n",
            "  1%|          | 42/7979 [00:08<25:55,  5.10it/s]\u001b[A\n",
            "  1%|          | 43/7979 [00:08<25:48,  5.13it/s]\u001b[A\n",
            "  1%|          | 44/7979 [00:08<26:09,  5.06it/s]\u001b[A\n",
            "  1%|          | 45/7979 [00:08<26:02,  5.08it/s]\u001b[A\n",
            "  1%|          | 46/7979 [00:09<25:38,  5.16it/s]\u001b[A\n",
            "  1%|          | 47/7979 [00:09<25:29,  5.18it/s]\u001b[A\n",
            "  1%|          | 48/7979 [00:09<25:36,  5.16it/s]\u001b[A\n",
            "  1%|          | 49/7979 [00:09<25:18,  5.22it/s]\u001b[A\n",
            "  1%|          | 50/7979 [00:09<25:38,  5.15it/s]\u001b[A\n",
            "  1%|          | 51/7979 [00:10<26:07,  5.06it/s]\u001b[A\n",
            "  1%|          | 52/7979 [00:10<25:45,  5.13it/s]\u001b[A\n",
            "  1%|          | 53/7979 [00:10<25:57,  5.09it/s]\u001b[A\n",
            "  1%|          | 54/7979 [00:10<25:54,  5.10it/s]\u001b[A\n",
            "  1%|          | 55/7979 [00:10<25:25,  5.19it/s]\u001b[A\n",
            "  1%|          | 56/7979 [00:11<26:12,  5.04it/s]\u001b[A\n",
            "  1%|          | 57/7979 [00:11<25:44,  5.13it/s]\u001b[A\n",
            "  1%|          | 58/7979 [00:11<26:42,  4.94it/s]\u001b[A\n",
            "  1%|          | 59/7979 [00:11<26:21,  5.01it/s]\u001b[A\n",
            "  1%|          | 60/7979 [00:11<26:57,  4.89it/s]\u001b[A\n",
            "  1%|          | 61/7979 [00:12<26:15,  5.03it/s]\u001b[A\n",
            "  1%|          | 62/7979 [00:12<26:07,  5.05it/s]\u001b[A\n",
            "  1%|          | 63/7979 [00:12<25:47,  5.11it/s]\u001b[A\n",
            "  1%|          | 64/7979 [00:12<25:46,  5.12it/s]\u001b[A\n",
            "  1%|          | 65/7979 [00:12<26:08,  5.04it/s]\u001b[A\n",
            "  1%|          | 66/7979 [00:13<26:18,  5.01it/s]\u001b[A\n",
            "  1%|          | 67/7979 [00:13<26:17,  5.01it/s]\u001b[A\n",
            "  1%|          | 68/7979 [00:13<25:55,  5.09it/s]\u001b[A\n",
            "  1%|          | 69/7979 [00:13<25:44,  5.12it/s]\u001b[A\n",
            "  1%|          | 70/7979 [00:13<25:40,  5.13it/s]\u001b[A\n",
            "  1%|          | 71/7979 [00:14<25:38,  5.14it/s]\u001b[A\n",
            "  1%|          | 72/7979 [00:14<26:07,  5.05it/s]\u001b[A\n",
            "  1%|          | 73/7979 [00:14<26:50,  4.91it/s]\u001b[A\n",
            "  1%|          | 74/7979 [00:14<27:05,  4.86it/s]\u001b[A\n",
            "  1%|          | 75/7979 [00:14<26:51,  4.91it/s]\u001b[A\n",
            "  1%|          | 76/7979 [00:15<26:17,  5.01it/s]\u001b[A\n",
            "  1%|          | 77/7979 [00:15<26:08,  5.04it/s]\u001b[A\n",
            "  1%|          | 78/7979 [00:15<25:54,  5.08it/s]\u001b[A\n",
            "  1%|          | 79/7979 [00:15<26:19,  5.00it/s]\u001b[A\n",
            "  1%|          | 80/7979 [00:15<25:52,  5.09it/s]\u001b[A\n",
            "  1%|          | 81/7979 [00:15<25:33,  5.15it/s]\u001b[A\n",
            "  1%|          | 82/7979 [00:16<25:34,  5.15it/s]\u001b[A\n",
            "  1%|          | 83/7979 [00:16<26:06,  5.04it/s]\u001b[A\n",
            "  1%|          | 84/7979 [00:16<26:49,  4.91it/s]\u001b[A\n",
            "  1%|          | 85/7979 [00:16<26:06,  5.04it/s]\u001b[A\n",
            "  1%|          | 86/7979 [00:16<25:35,  5.14it/s]\u001b[A\n",
            "  1%|          | 87/7979 [00:17<25:48,  5.10it/s]\u001b[A\n",
            "  1%|          | 88/7979 [00:17<25:57,  5.07it/s]\u001b[A\n",
            "  1%|          | 89/7979 [00:17<25:51,  5.09it/s]\u001b[A\n",
            "  1%|          | 90/7979 [00:17<26:10,  5.02it/s]\u001b[A\n",
            "  1%|          | 91/7979 [00:17<25:36,  5.13it/s]\u001b[A\n",
            "  1%|          | 92/7979 [00:18<25:51,  5.08it/s]\u001b[A\n",
            "  1%|          | 93/7979 [00:18<25:37,  5.13it/s]\u001b[A\n",
            "  1%|          | 94/7979 [00:18<25:27,  5.16it/s]\u001b[A\n",
            "  1%|          | 95/7979 [00:18<25:09,  5.22it/s]\u001b[A\n",
            "  1%|          | 96/7979 [00:18<25:29,  5.16it/s]\u001b[A\n",
            "  1%|          | 97/7979 [00:19<25:19,  5.19it/s]\u001b[A\n",
            "  1%|          | 98/7979 [00:19<25:25,  5.17it/s]\u001b[A\n",
            "  1%|          | 99/7979 [00:19<25:17,  5.19it/s]\u001b[A\n",
            "  1%|▏         | 100/7979 [00:19<25:03,  5.24it/s]\u001b[A\n",
            "  1%|▏         | 101/7979 [00:19<25:02,  5.24it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.1833244413137436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|▏         | 102/7979 [00:20<25:45,  5.10it/s]\u001b[A\n",
            "  1%|▏         | 103/7979 [00:20<25:54,  5.07it/s]\u001b[A\n",
            "  1%|▏         | 104/7979 [00:20<26:23,  4.97it/s]\u001b[A\n",
            "  1%|▏         | 105/7979 [00:20<26:17,  4.99it/s]\u001b[A\n",
            "  1%|▏         | 106/7979 [00:20<26:16,  4.99it/s]\u001b[A\n",
            "  1%|▏         | 107/7979 [00:21<26:09,  5.01it/s]\u001b[A\n",
            "  1%|▏         | 108/7979 [00:21<25:56,  5.06it/s]\u001b[A\n",
            "  1%|▏         | 109/7979 [00:21<26:36,  4.93it/s]\u001b[A\n",
            "  1%|▏         | 110/7979 [00:21<26:41,  4.91it/s]\u001b[A\n",
            "  1%|▏         | 111/7979 [00:21<26:11,  5.01it/s]\u001b[A\n",
            "  1%|▏         | 112/7979 [00:22<26:06,  5.02it/s]\u001b[A\n",
            "  1%|▏         | 113/7979 [00:22<25:44,  5.09it/s]\u001b[A\n",
            "  1%|▏         | 114/7979 [00:22<25:52,  5.07it/s]\u001b[A\n",
            "  1%|▏         | 115/7979 [00:22<25:45,  5.09it/s]\u001b[A\n",
            "  1%|▏         | 116/7979 [00:22<25:42,  5.10it/s]\u001b[A\n",
            "  1%|▏         | 117/7979 [00:23<26:09,  5.01it/s]\u001b[A\n",
            "  1%|▏         | 118/7979 [00:23<25:57,  5.05it/s]\u001b[A\n",
            "  1%|▏         | 119/7979 [00:23<25:39,  5.10it/s]\u001b[A\n",
            "  2%|▏         | 120/7979 [00:23<25:49,  5.07it/s]\u001b[A\n",
            "  2%|▏         | 121/7979 [00:23<25:42,  5.09it/s]\u001b[A\n",
            "  2%|▏         | 122/7979 [00:24<27:17,  4.80it/s]\u001b[A\n",
            "  2%|▏         | 123/7979 [00:24<26:49,  4.88it/s]\u001b[A\n",
            "  2%|▏         | 124/7979 [00:24<26:40,  4.91it/s]\u001b[A\n",
            "  2%|▏         | 125/7979 [00:24<25:57,  5.04it/s]\u001b[A\n",
            "  2%|▏         | 126/7979 [00:24<26:48,  4.88it/s]\u001b[A\n",
            "  2%|▏         | 127/7979 [00:25<26:24,  4.96it/s]\u001b[A\n",
            "  2%|▏         | 128/7979 [00:25<26:50,  4.88it/s]\u001b[A\n",
            "  2%|▏         | 129/7979 [00:25<26:37,  4.91it/s]\u001b[A\n",
            "  2%|▏         | 130/7979 [00:25<26:41,  4.90it/s]\u001b[A\n",
            "  2%|▏         | 131/7979 [00:25<27:09,  4.82it/s]\u001b[A\n",
            "  2%|▏         | 132/7979 [00:26<26:32,  4.93it/s]\u001b[A\n",
            "  2%|▏         | 133/7979 [00:26<26:30,  4.93it/s]\u001b[A\n",
            "  2%|▏         | 134/7979 [00:26<26:04,  5.01it/s]\u001b[A\n",
            "  2%|▏         | 135/7979 [00:26<26:20,  4.96it/s]\u001b[A\n",
            "  2%|▏         | 136/7979 [00:26<25:41,  5.09it/s]\u001b[A\n",
            "  2%|▏         | 137/7979 [00:27<25:30,  5.12it/s]\u001b[A\n",
            "  2%|▏         | 138/7979 [00:27<25:40,  5.09it/s]\u001b[A\n",
            "  2%|▏         | 139/7979 [00:27<25:22,  5.15it/s]\u001b[A\n",
            "  2%|▏         | 140/7979 [00:27<25:22,  5.15it/s]\u001b[A\n",
            "  2%|▏         | 141/7979 [00:27<25:10,  5.19it/s]\u001b[A\n",
            "  2%|▏         | 142/7979 [00:28<25:12,  5.18it/s]\u001b[A\n",
            "  2%|▏         | 143/7979 [00:28<25:17,  5.16it/s]\u001b[A\n",
            "  2%|▏         | 144/7979 [00:28<25:24,  5.14it/s]\u001b[A\n",
            "  2%|▏         | 145/7979 [00:28<26:01,  5.02it/s]\u001b[A\n",
            "  2%|▏         | 146/7979 [00:28<25:43,  5.07it/s]\u001b[A\n",
            "  2%|▏         | 147/7979 [00:29<25:31,  5.11it/s]\u001b[A\n",
            "  2%|▏         | 148/7979 [00:29<25:30,  5.12it/s]\u001b[A\n",
            "  2%|▏         | 149/7979 [00:29<25:22,  5.14it/s]\u001b[A\n",
            "  2%|▏         | 150/7979 [00:29<25:49,  5.05it/s]\u001b[A\n",
            "  2%|▏         | 151/7979 [00:29<26:00,  5.02it/s]\u001b[A\n",
            "  2%|▏         | 152/7979 [00:30<26:07,  4.99it/s]\u001b[A\n",
            "  2%|▏         | 153/7979 [00:30<25:59,  5.02it/s]\u001b[A\n",
            "  2%|▏         | 154/7979 [00:30<25:53,  5.04it/s]\u001b[A\n",
            "  2%|▏         | 155/7979 [00:30<25:31,  5.11it/s]\u001b[A\n",
            "  2%|▏         | 156/7979 [00:30<25:23,  5.14it/s]\u001b[A\n",
            "  2%|▏         | 157/7979 [00:31<25:32,  5.10it/s]\u001b[A\n",
            "  2%|▏         | 158/7979 [00:31<25:17,  5.16it/s]\u001b[A\n",
            "  2%|▏         | 159/7979 [00:31<25:20,  5.14it/s]\u001b[A\n",
            "  2%|▏         | 160/7979 [00:31<25:56,  5.03it/s]\u001b[A\n",
            "  2%|▏         | 161/7979 [00:31<25:33,  5.10it/s]\u001b[A\n",
            "  2%|▏         | 162/7979 [00:32<25:11,  5.17it/s]\u001b[A\n",
            "  2%|▏         | 163/7979 [00:32<25:40,  5.07it/s]\u001b[A\n",
            "  2%|▏         | 164/7979 [00:32<25:56,  5.02it/s]\u001b[A\n",
            "  2%|▏         | 165/7979 [00:32<25:30,  5.11it/s]\u001b[A\n",
            "  2%|▏         | 166/7979 [00:32<25:44,  5.06it/s]\u001b[A\n",
            "  2%|▏         | 167/7979 [00:33<25:43,  5.06it/s]\u001b[A\n",
            "  2%|▏         | 168/7979 [00:33<25:58,  5.01it/s]\u001b[A\n",
            "  2%|▏         | 169/7979 [00:33<25:53,  5.03it/s]\u001b[A\n",
            "  2%|▏         | 170/7979 [00:33<25:34,  5.09it/s]\u001b[A\n",
            "  2%|▏         | 171/7979 [00:33<25:23,  5.12it/s]\u001b[A\n",
            "  2%|▏         | 172/7979 [00:33<25:22,  5.13it/s]\u001b[A\n",
            "  2%|▏         | 173/7979 [00:34<25:20,  5.13it/s]\u001b[A\n",
            "  2%|▏         | 174/7979 [00:34<25:56,  5.01it/s]\u001b[A\n",
            "  2%|▏         | 175/7979 [00:34<25:37,  5.07it/s]\u001b[A\n",
            "  2%|▏         | 176/7979 [00:34<25:43,  5.06it/s]\u001b[A\n",
            "  2%|▏         | 177/7979 [00:34<25:34,  5.08it/s]\u001b[A\n",
            "  2%|▏         | 178/7979 [00:35<25:38,  5.07it/s]\u001b[A\n",
            "  2%|▏         | 179/7979 [00:35<25:22,  5.12it/s]\u001b[A\n",
            "  2%|▏         | 180/7979 [00:35<24:53,  5.22it/s]\u001b[A\n",
            "  2%|▏         | 181/7979 [00:35<25:51,  5.02it/s]\u001b[A\n",
            "  2%|▏         | 182/7979 [00:35<25:37,  5.07it/s]\u001b[A\n",
            "  2%|▏         | 183/7979 [00:36<25:33,  5.08it/s]\u001b[A\n",
            "  2%|▏         | 184/7979 [00:36<25:23,  5.12it/s]\u001b[A\n",
            "  2%|▏         | 185/7979 [00:36<25:49,  5.03it/s]\u001b[A\n",
            "  2%|▏         | 186/7979 [00:36<25:33,  5.08it/s]\u001b[A\n",
            "  2%|▏         | 187/7979 [00:36<25:08,  5.17it/s]\u001b[A\n",
            "  2%|▏         | 188/7979 [00:37<24:59,  5.19it/s]\u001b[A\n",
            "  2%|▏         | 189/7979 [00:37<25:22,  5.12it/s]\u001b[A\n",
            "  2%|▏         | 190/7979 [00:37<25:20,  5.12it/s]\u001b[A\n",
            "  2%|▏         | 191/7979 [00:37<25:16,  5.14it/s]\u001b[A\n",
            "  2%|▏         | 192/7979 [00:37<26:07,  4.97it/s]\u001b[A\n",
            "  2%|▏         | 193/7979 [00:38<25:58,  5.00it/s]\u001b[A\n",
            "  2%|▏         | 194/7979 [00:38<25:29,  5.09it/s]\u001b[A\n",
            "  2%|▏         | 195/7979 [00:38<25:13,  5.14it/s]\u001b[A\n",
            "  2%|▏         | 196/7979 [00:38<25:25,  5.10it/s]\u001b[A\n",
            "  2%|▏         | 197/7979 [00:38<25:23,  5.11it/s]\u001b[A\n",
            "  2%|▏         | 198/7979 [00:39<25:12,  5.14it/s]\u001b[A\n",
            "  2%|▏         | 199/7979 [00:39<25:03,  5.17it/s]\u001b[A\n",
            "  3%|▎         | 200/7979 [00:39<25:00,  5.18it/s]\u001b[A\n",
            "  3%|▎         | 201/7979 [00:39<25:04,  5.17it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.22625665366649628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  3%|▎         | 202/7979 [00:39<25:00,  5.18it/s]\u001b[A\n",
            "  3%|▎         | 203/7979 [00:40<26:06,  4.96it/s]\u001b[A\n",
            "  3%|▎         | 204/7979 [00:40<26:22,  4.91it/s]\u001b[A\n",
            "  3%|▎         | 205/7979 [00:40<25:46,  5.03it/s]\u001b[A\n",
            "  3%|▎         | 206/7979 [00:40<25:47,  5.02it/s]\u001b[A\n",
            "  3%|▎         | 207/7979 [00:40<25:25,  5.09it/s]\u001b[A\n",
            "  3%|▎         | 208/7979 [00:41<25:07,  5.15it/s]\u001b[A\n",
            "  3%|▎         | 209/7979 [00:41<25:04,  5.17it/s]\u001b[A\n",
            "  3%|▎         | 210/7979 [00:41<25:05,  5.16it/s]\u001b[A\n",
            "  3%|▎         | 211/7979 [00:41<24:44,  5.23it/s]\u001b[A\n",
            "  3%|▎         | 212/7979 [00:41<25:08,  5.15it/s]\u001b[A\n",
            "  3%|▎         | 213/7979 [00:42<25:02,  5.17it/s]\u001b[A\n",
            "  3%|▎         | 214/7979 [00:42<24:57,  5.19it/s]\u001b[A\n",
            "  3%|▎         | 215/7979 [00:42<25:00,  5.17it/s]\u001b[A\n",
            "  3%|▎         | 216/7979 [00:42<25:18,  5.11it/s]\u001b[A\n",
            "  3%|▎         | 217/7979 [00:42<25:07,  5.15it/s]\u001b[A\n",
            "  3%|▎         | 218/7979 [00:43<25:32,  5.07it/s]\u001b[A\n",
            "  3%|▎         | 219/7979 [00:43<25:17,  5.12it/s]\u001b[A\n",
            "  3%|▎         | 220/7979 [00:43<24:57,  5.18it/s]\u001b[A\n",
            "  3%|▎         | 221/7979 [00:43<25:05,  5.15it/s]\u001b[A\n",
            "  3%|▎         | 222/7979 [00:43<25:34,  5.05it/s]\u001b[A\n",
            "  3%|▎         | 223/7979 [00:43<25:51,  5.00it/s]\u001b[A\n",
            "  3%|▎         | 224/7979 [00:44<25:25,  5.08it/s]\u001b[A\n",
            "  3%|▎         | 225/7979 [00:44<25:08,  5.14it/s]\u001b[A\n",
            "  3%|▎         | 226/7979 [00:44<24:50,  5.20it/s]\u001b[A\n",
            "  3%|▎         | 227/7979 [00:44<24:55,  5.18it/s]\u001b[A\n",
            "  3%|▎         | 228/7979 [00:44<25:09,  5.13it/s]\u001b[A\n",
            "  3%|▎         | 229/7979 [00:45<25:25,  5.08it/s]\u001b[A\n",
            "  3%|▎         | 230/7979 [00:45<25:12,  5.12it/s]\u001b[A\n",
            "  3%|▎         | 231/7979 [00:45<24:56,  5.18it/s]\u001b[A\n",
            "  3%|▎         | 232/7979 [00:45<24:35,  5.25it/s]\u001b[A\n",
            "  3%|▎         | 233/7979 [00:45<24:36,  5.25it/s]\u001b[A\n",
            "  3%|▎         | 234/7979 [00:46<24:38,  5.24it/s]\u001b[A\n",
            "  3%|▎         | 235/7979 [00:46<25:00,  5.16it/s]\u001b[A\n",
            "  3%|▎         | 236/7979 [00:46<25:33,  5.05it/s]\u001b[A\n",
            "  3%|▎         | 237/7979 [00:46<25:44,  5.01it/s]\u001b[A\n",
            "  3%|▎         | 238/7979 [00:46<26:02,  4.95it/s]\u001b[A\n",
            "  3%|▎         | 239/7979 [00:47<25:41,  5.02it/s]\u001b[A\n",
            "  3%|▎         | 240/7979 [00:47<25:12,  5.12it/s]\u001b[A\n",
            "  3%|▎         | 241/7979 [00:47<24:51,  5.19it/s]\u001b[A\n",
            "  3%|▎         | 242/7979 [00:47<24:52,  5.19it/s]\u001b[A\n",
            "  3%|▎         | 243/7979 [00:47<25:32,  5.05it/s]\u001b[A\n",
            "  3%|▎         | 244/7979 [00:48<25:26,  5.07it/s]\u001b[A\n",
            "  3%|▎         | 245/7979 [00:48<25:19,  5.09it/s]\u001b[A\n",
            "  3%|▎         | 246/7979 [00:48<25:22,  5.08it/s]\u001b[A\n",
            "  3%|▎         | 247/7979 [00:48<25:54,  4.97it/s]\u001b[A\n",
            "  3%|▎         | 248/7979 [00:48<25:28,  5.06it/s]\u001b[A\n",
            "  3%|▎         | 249/7979 [00:49<26:01,  4.95it/s]\u001b[A\n",
            "  3%|▎         | 250/7979 [00:49<26:09,  4.92it/s]\u001b[A\n",
            "  3%|▎         | 251/7979 [00:49<25:31,  5.05it/s]\u001b[A\n",
            "  3%|▎         | 252/7979 [00:49<25:13,  5.10it/s]\u001b[A\n",
            "  3%|▎         | 253/7979 [00:49<25:36,  5.03it/s]\u001b[A\n",
            "  3%|▎         | 254/7979 [00:50<25:23,  5.07it/s]\u001b[A\n",
            "  3%|▎         | 255/7979 [00:50<25:08,  5.12it/s]\u001b[A\n",
            "  3%|▎         | 256/7979 [00:50<24:56,  5.16it/s]\u001b[A\n",
            "  3%|▎         | 257/7979 [00:50<24:53,  5.17it/s]\u001b[A\n",
            "  3%|▎         | 258/7979 [00:50<25:03,  5.14it/s]\u001b[A\n",
            "  3%|▎         | 259/7979 [00:51<24:49,  5.18it/s]\u001b[A\n",
            "  3%|▎         | 260/7979 [00:51<25:24,  5.06it/s]\u001b[A\n",
            "  3%|▎         | 261/7979 [00:51<25:15,  5.09it/s]\u001b[A\n",
            "  3%|▎         | 262/7979 [00:51<25:06,  5.12it/s]\u001b[A\n",
            "  3%|▎         | 263/7979 [00:51<24:46,  5.19it/s]\u001b[A\n",
            "  3%|▎         | 264/7979 [00:51<24:38,  5.22it/s]\u001b[A\n",
            "  3%|▎         | 265/7979 [00:52<24:34,  5.23it/s]\u001b[A\n",
            "  3%|▎         | 266/7979 [00:52<25:31,  5.04it/s]\u001b[A\n",
            "  3%|▎         | 267/7979 [00:52<25:09,  5.11it/s]\u001b[A\n",
            "  3%|▎         | 268/7979 [00:52<25:24,  5.06it/s]\u001b[A\n",
            "  3%|▎         | 269/7979 [00:53<25:38,  5.01it/s]\u001b[A\n",
            "  3%|▎         | 270/7979 [00:53<25:34,  5.02it/s]\u001b[A\n",
            "  3%|▎         | 271/7979 [00:53<25:16,  5.08it/s]\u001b[A\n",
            "  3%|▎         | 272/7979 [00:53<25:15,  5.08it/s]\u001b[A\n",
            "  3%|▎         | 273/7979 [00:53<25:21,  5.06it/s]\u001b[A\n",
            "  3%|▎         | 274/7979 [00:53<24:50,  5.17it/s]\u001b[A\n",
            "  3%|▎         | 275/7979 [00:54<25:08,  5.11it/s]\u001b[A\n",
            "  3%|▎         | 276/7979 [00:54<24:59,  5.14it/s]\u001b[A\n",
            "  3%|▎         | 277/7979 [00:54<25:16,  5.08it/s]\u001b[A\n",
            "  3%|▎         | 278/7979 [00:54<25:00,  5.13it/s]\u001b[A\n",
            "  3%|▎         | 279/7979 [00:54<24:51,  5.16it/s]\u001b[A\n",
            "  4%|▎         | 280/7979 [00:55<24:29,  5.24it/s]\u001b[A\n",
            "  4%|▎         | 281/7979 [00:55<25:12,  5.09it/s]\u001b[A\n",
            "  4%|▎         | 282/7979 [00:55<25:17,  5.07it/s]\u001b[A\n",
            "  4%|▎         | 283/7979 [00:55<25:36,  5.01it/s]\u001b[A\n",
            "  4%|▎         | 284/7979 [00:55<25:27,  5.04it/s]\u001b[A\n",
            "  4%|▎         | 285/7979 [00:56<25:31,  5.02it/s]\u001b[A\n",
            "  4%|▎         | 286/7979 [00:56<25:10,  5.09it/s]\u001b[A\n",
            "  4%|▎         | 287/7979 [00:56<25:29,  5.03it/s]\u001b[A\n",
            "  4%|▎         | 288/7979 [00:56<25:35,  5.01it/s]\u001b[A\n",
            "  4%|▎         | 289/7979 [00:56<25:31,  5.02it/s]\u001b[A\n",
            "  4%|▎         | 290/7979 [00:57<25:17,  5.07it/s]\u001b[A\n",
            "  4%|▎         | 291/7979 [00:57<25:15,  5.07it/s]\u001b[A\n",
            "  4%|▎         | 292/7979 [00:57<26:33,  4.82it/s]\u001b[A\n",
            "  4%|▎         | 293/7979 [00:57<26:02,  4.92it/s]\u001b[A\n",
            "  4%|▎         | 294/7979 [00:57<26:08,  4.90it/s]\u001b[A\n",
            "  4%|▎         | 295/7979 [00:58<25:44,  4.97it/s]\u001b[A\n",
            "  4%|▎         | 296/7979 [00:58<25:22,  5.04it/s]\u001b[A\n",
            "  4%|▎         | 297/7979 [00:58<25:01,  5.12it/s]\u001b[A\n",
            "  4%|▎         | 298/7979 [00:58<24:40,  5.19it/s]\u001b[A\n",
            "  4%|▎         | 299/7979 [00:58<24:34,  5.21it/s]\u001b[A\n",
            "  4%|▍         | 300/7979 [00:59<24:45,  5.17it/s]\u001b[A\n",
            "  4%|▍         | 301/7979 [00:59<26:29,  4.83it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.07685349881649017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  4%|▍         | 302/7979 [00:59<25:52,  4.95it/s]\u001b[A\n",
            "  4%|▍         | 303/7979 [00:59<25:40,  4.98it/s]\u001b[A\n",
            "  4%|▍         | 304/7979 [00:59<26:04,  4.91it/s]\u001b[A\n",
            "  4%|▍         | 305/7979 [01:00<25:50,  4.95it/s]\u001b[A\n",
            "  4%|▍         | 306/7979 [01:00<25:28,  5.02it/s]\u001b[A\n",
            "  4%|▍         | 307/7979 [01:00<25:11,  5.08it/s]\u001b[A\n",
            "  4%|▍         | 308/7979 [01:00<25:05,  5.09it/s]\u001b[A\n",
            "  4%|▍         | 309/7979 [01:00<25:19,  5.05it/s]\u001b[A\n",
            "  4%|▍         | 310/7979 [01:01<24:57,  5.12it/s]\u001b[A\n",
            "  4%|▍         | 311/7979 [01:01<24:39,  5.18it/s]\u001b[A\n",
            "  4%|▍         | 312/7979 [01:01<24:36,  5.19it/s]\u001b[A\n",
            "  4%|▍         | 313/7979 [01:01<24:28,  5.22it/s]\u001b[A\n",
            "  4%|▍         | 314/7979 [01:01<24:25,  5.23it/s]\u001b[A\n",
            "  4%|▍         | 315/7979 [01:02<24:34,  5.20it/s]\u001b[A\n",
            "  4%|▍         | 316/7979 [01:02<24:34,  5.20it/s]\u001b[A\n",
            "  4%|▍         | 317/7979 [01:02<24:34,  5.19it/s]\u001b[A\n",
            "  4%|▍         | 318/7979 [01:02<24:53,  5.13it/s]\u001b[A\n",
            "  4%|▍         | 319/7979 [01:02<25:08,  5.08it/s]\u001b[A\n",
            "  4%|▍         | 320/7979 [01:03<24:42,  5.17it/s]\u001b[A\n",
            "  4%|▍         | 321/7979 [01:03<24:30,  5.21it/s]\u001b[A\n",
            "  4%|▍         | 322/7979 [01:03<25:17,  5.05it/s]\u001b[A\n",
            "  4%|▍         | 323/7979 [01:03<25:27,  5.01it/s]\u001b[A\n",
            "  4%|▍         | 324/7979 [01:03<25:14,  5.05it/s]\u001b[A\n",
            "  4%|▍         | 325/7979 [01:04<25:30,  5.00it/s]\u001b[A\n",
            "  4%|▍         | 326/7979 [01:04<25:41,  4.96it/s]\u001b[A\n",
            "  4%|▍         | 327/7979 [01:04<25:09,  5.07it/s]\u001b[A\n",
            "  4%|▍         | 328/7979 [01:04<25:14,  5.05it/s]\u001b[A\n",
            "  4%|▍         | 329/7979 [01:04<24:56,  5.11it/s]\u001b[A\n",
            "  4%|▍         | 330/7979 [01:05<24:45,  5.15it/s]\u001b[A\n",
            "  4%|▍         | 331/7979 [01:05<24:59,  5.10it/s]\u001b[A\n",
            "  4%|▍         | 332/7979 [01:05<25:06,  5.08it/s]\u001b[A\n",
            "  4%|▍         | 333/7979 [01:05<24:42,  5.16it/s]\u001b[A\n",
            "  4%|▍         | 334/7979 [01:05<24:33,  5.19it/s]\u001b[A\n",
            "  4%|▍         | 335/7979 [01:05<24:59,  5.10it/s]\u001b[A\n",
            "  4%|▍         | 336/7979 [01:06<25:03,  5.08it/s]\u001b[A\n",
            "  4%|▍         | 337/7979 [01:06<24:54,  5.12it/s]\u001b[A\n",
            "  4%|▍         | 338/7979 [01:06<25:42,  4.95it/s]\u001b[A\n",
            "  4%|▍         | 339/7979 [01:06<25:15,  5.04it/s]\u001b[A\n",
            "  4%|▍         | 340/7979 [01:06<24:54,  5.11it/s]\u001b[A\n",
            "  4%|▍         | 341/7979 [01:07<24:59,  5.09it/s]\u001b[A\n",
            "  4%|▍         | 342/7979 [01:07<25:09,  5.06it/s]\u001b[A\n",
            "  4%|▍         | 343/7979 [01:07<25:07,  5.07it/s]\u001b[A\n",
            "  4%|▍         | 344/7979 [01:07<25:03,  5.08it/s]\u001b[A\n",
            "  4%|▍         | 345/7979 [01:07<24:51,  5.12it/s]\u001b[A\n",
            "  4%|▍         | 346/7979 [01:08<24:29,  5.20it/s]\u001b[A\n",
            "  4%|▍         | 347/7979 [01:08<25:46,  4.93it/s]\u001b[A\n",
            "  4%|▍         | 348/7979 [01:08<25:35,  4.97it/s]\u001b[A\n",
            "  4%|▍         | 349/7979 [01:08<25:59,  4.89it/s]\u001b[A\n",
            "  4%|▍         | 350/7979 [01:08<26:01,  4.88it/s]\u001b[A\n",
            "  4%|▍         | 351/7979 [01:09<25:29,  4.99it/s]\u001b[A\n",
            "  4%|▍         | 352/7979 [01:09<25:44,  4.94it/s]\u001b[A\n",
            "  4%|▍         | 353/7979 [01:09<25:19,  5.02it/s]\u001b[A\n",
            "  4%|▍         | 354/7979 [01:09<25:53,  4.91it/s]\u001b[A\n",
            "  4%|▍         | 355/7979 [01:10<26:49,  4.74it/s]\u001b[A\n",
            "  4%|▍         | 356/7979 [01:10<26:29,  4.80it/s]\u001b[A\n",
            "  4%|▍         | 357/7979 [01:10<25:59,  4.89it/s]\u001b[A\n",
            "  4%|▍         | 358/7979 [01:10<25:44,  4.94it/s]\u001b[A\n",
            "  4%|▍         | 359/7979 [01:10<25:33,  4.97it/s]\u001b[A\n",
            "  5%|▍         | 360/7979 [01:11<25:47,  4.92it/s]\u001b[A\n",
            "  5%|▍         | 361/7979 [01:11<25:50,  4.91it/s]\u001b[A\n",
            "  5%|▍         | 362/7979 [01:11<25:39,  4.95it/s]\u001b[A\n",
            "  5%|▍         | 363/7979 [01:11<25:26,  4.99it/s]\u001b[A\n",
            "  5%|▍         | 364/7979 [01:11<25:09,  5.04it/s]\u001b[A\n",
            "  5%|▍         | 365/7979 [01:12<24:50,  5.11it/s]\u001b[A\n",
            "  5%|▍         | 366/7979 [01:12<24:47,  5.12it/s]\u001b[A\n",
            "  5%|▍         | 367/7979 [01:12<24:38,  5.15it/s]\u001b[A\n",
            "  5%|▍         | 368/7979 [01:12<25:36,  4.95it/s]\u001b[A\n",
            "  5%|▍         | 369/7979 [01:12<25:42,  4.93it/s]\u001b[A\n",
            "  5%|▍         | 370/7979 [01:13<26:10,  4.84it/s]\u001b[A\n",
            "  5%|▍         | 371/7979 [01:13<25:56,  4.89it/s]\u001b[A\n",
            "  5%|▍         | 372/7979 [01:13<26:02,  4.87it/s]\u001b[A\n",
            "  5%|▍         | 373/7979 [01:13<25:30,  4.97it/s]\u001b[A\n",
            "  5%|▍         | 374/7979 [01:13<25:17,  5.01it/s]\u001b[A\n",
            "  5%|▍         | 375/7979 [01:14<25:01,  5.07it/s]\u001b[A\n",
            "  5%|▍         | 376/7979 [01:14<24:52,  5.10it/s]\u001b[A\n",
            "  5%|▍         | 377/7979 [01:14<24:43,  5.12it/s]\u001b[A\n",
            "  5%|▍         | 378/7979 [01:14<24:37,  5.14it/s]\u001b[A\n",
            "  5%|▍         | 379/7979 [01:14<25:24,  4.99it/s]\u001b[A\n",
            "  5%|▍         | 380/7979 [01:15<25:29,  4.97it/s]\u001b[A\n",
            "  5%|▍         | 381/7979 [01:15<25:08,  5.04it/s]\u001b[A\n",
            "  5%|▍         | 382/7979 [01:15<25:16,  5.01it/s]\u001b[A\n",
            "  5%|▍         | 383/7979 [01:15<25:32,  4.96it/s]\u001b[A\n",
            "  5%|▍         | 384/7979 [01:15<25:12,  5.02it/s]\u001b[A\n",
            "  5%|▍         | 385/7979 [01:16<24:55,  5.08it/s]\u001b[A\n",
            "  5%|▍         | 386/7979 [01:16<24:39,  5.13it/s]\u001b[A\n",
            "  5%|▍         | 387/7979 [01:16<24:50,  5.09it/s]\u001b[A\n",
            "  5%|▍         | 388/7979 [01:16<24:40,  5.13it/s]\u001b[A\n",
            "  5%|▍         | 389/7979 [01:16<24:55,  5.08it/s]\u001b[A\n",
            "  5%|▍         | 390/7979 [01:16<25:21,  4.99it/s]\u001b[A\n",
            "  5%|▍         | 391/7979 [01:17<24:57,  5.07it/s]\u001b[A\n",
            "  5%|▍         | 392/7979 [01:17<25:00,  5.06it/s]\u001b[A\n",
            "  5%|▍         | 393/7979 [01:17<25:09,  5.02it/s]\u001b[A\n",
            "  5%|▍         | 394/7979 [01:17<25:25,  4.97it/s]\u001b[A\n",
            "  5%|▍         | 395/7979 [01:17<25:29,  4.96it/s]\u001b[A\n",
            "  5%|▍         | 396/7979 [01:18<25:46,  4.90it/s]\u001b[A\n",
            "  5%|▍         | 397/7979 [01:18<25:18,  4.99it/s]\u001b[A\n",
            "  5%|▍         | 398/7979 [01:18<25:04,  5.04it/s]\u001b[A\n",
            "  5%|▌         | 399/7979 [01:18<24:44,  5.11it/s]\u001b[A\n",
            "  5%|▌         | 400/7979 [01:18<24:38,  5.12it/s]\u001b[A\n",
            "  5%|▌         | 401/7979 [01:19<25:21,  4.98it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.10536889731884003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  5%|▌         | 402/7979 [01:19<25:24,  4.97it/s]\u001b[A\n",
            "  5%|▌         | 403/7979 [01:19<25:16,  4.99it/s]\u001b[A\n",
            "  5%|▌         | 404/7979 [01:19<24:55,  5.06it/s]\u001b[A\n",
            "  5%|▌         | 405/7979 [01:19<24:46,  5.10it/s]\u001b[A\n",
            "  5%|▌         | 406/7979 [01:20<24:54,  5.07it/s]\u001b[A\n",
            "  5%|▌         | 407/7979 [01:20<24:36,  5.13it/s]\u001b[A\n",
            "  5%|▌         | 408/7979 [01:20<24:30,  5.15it/s]\u001b[A\n",
            "  5%|▌         | 409/7979 [01:20<24:30,  5.15it/s]\u001b[A\n",
            "  5%|▌         | 410/7979 [01:20<24:54,  5.07it/s]\u001b[A\n",
            "  5%|▌         | 411/7979 [01:21<25:47,  4.89it/s]\u001b[A\n",
            "  5%|▌         | 412/7979 [01:21<26:00,  4.85it/s]\u001b[A\n",
            "  5%|▌         | 413/7979 [01:21<25:36,  4.93it/s]\u001b[A\n",
            "  5%|▌         | 414/7979 [01:21<25:47,  4.89it/s]\u001b[A\n",
            "  5%|▌         | 415/7979 [01:21<25:16,  4.99it/s]\u001b[A\n",
            "  5%|▌         | 416/7979 [01:22<25:18,  4.98it/s]\u001b[A\n",
            "  5%|▌         | 417/7979 [01:22<25:20,  4.97it/s]\u001b[A\n",
            "  5%|▌         | 418/7979 [01:22<24:53,  5.06it/s]\u001b[A\n",
            "  5%|▌         | 419/7979 [01:22<24:33,  5.13it/s]\u001b[A\n",
            "  5%|▌         | 420/7979 [01:22<24:23,  5.17it/s]\u001b[A\n",
            "  5%|▌         | 421/7979 [01:23<24:22,  5.17it/s]\u001b[A\n",
            "  5%|▌         | 422/7979 [01:23<24:05,  5.23it/s]\u001b[A\n",
            "  5%|▌         | 423/7979 [01:23<25:00,  5.04it/s]\u001b[A\n",
            "  5%|▌         | 424/7979 [01:23<25:03,  5.03it/s]\u001b[A\n",
            "  5%|▌         | 425/7979 [01:23<25:00,  5.03it/s]\u001b[A\n",
            "  5%|▌         | 426/7979 [01:24<24:38,  5.11it/s]\u001b[A\n",
            "  5%|▌         | 427/7979 [01:24<24:38,  5.11it/s]\u001b[A\n",
            "  5%|▌         | 428/7979 [01:24<24:49,  5.07it/s]\u001b[A\n",
            "  5%|▌         | 429/7979 [01:24<24:22,  5.16it/s]\u001b[A\n",
            "  5%|▌         | 430/7979 [01:24<24:25,  5.15it/s]\u001b[A\n",
            "  5%|▌         | 431/7979 [01:25<24:18,  5.18it/s]\u001b[A\n",
            "  5%|▌         | 432/7979 [01:25<24:45,  5.08it/s]\u001b[A\n",
            "  5%|▌         | 433/7979 [01:25<24:41,  5.09it/s]\u001b[A\n",
            "  5%|▌         | 434/7979 [01:25<24:32,  5.12it/s]\u001b[A\n",
            "  5%|▌         | 435/7979 [01:25<25:07,  5.00it/s]\u001b[A\n",
            "  5%|▌         | 436/7979 [01:26<24:40,  5.10it/s]\u001b[A\n",
            "  5%|▌         | 437/7979 [01:26<24:33,  5.12it/s]\u001b[A\n",
            "  5%|▌         | 438/7979 [01:26<24:19,  5.17it/s]\u001b[A\n",
            "  6%|▌         | 439/7979 [01:26<24:08,  5.20it/s]\u001b[A\n",
            "  6%|▌         | 440/7979 [01:26<24:21,  5.16it/s]\u001b[A\n",
            "  6%|▌         | 441/7979 [01:27<24:35,  5.11it/s]\u001b[A\n",
            "  6%|▌         | 442/7979 [01:27<24:27,  5.14it/s]\u001b[A\n",
            "  6%|▌         | 443/7979 [01:27<24:21,  5.16it/s]\u001b[A\n",
            "  6%|▌         | 444/7979 [01:27<24:08,  5.20it/s]\u001b[A\n",
            "  6%|▌         | 445/7979 [01:27<24:22,  5.15it/s]\u001b[A\n",
            "  6%|▌         | 446/7979 [01:28<24:19,  5.16it/s]\u001b[A\n",
            "  6%|▌         | 447/7979 [01:28<24:43,  5.08it/s]\u001b[A\n",
            "  6%|▌         | 448/7979 [01:28<24:36,  5.10it/s]\u001b[A\n",
            "  6%|▌         | 449/7979 [01:28<24:58,  5.03it/s]\u001b[A\n",
            "  6%|▌         | 450/7979 [01:28<24:48,  5.06it/s]\u001b[A\n",
            "  6%|▌         | 451/7979 [01:29<25:08,  4.99it/s]\u001b[A\n",
            "  6%|▌         | 452/7979 [01:29<25:28,  4.93it/s]\u001b[A\n",
            "  6%|▌         | 453/7979 [01:29<25:44,  4.87it/s]\u001b[A\n",
            "  6%|▌         | 454/7979 [01:29<25:30,  4.92it/s]\u001b[A\n",
            "  6%|▌         | 455/7979 [01:29<25:15,  4.97it/s]\u001b[A\n",
            "  6%|▌         | 456/7979 [01:30<24:44,  5.07it/s]\u001b[A\n",
            "  6%|▌         | 457/7979 [01:30<25:00,  5.01it/s]\u001b[A\n",
            "  6%|▌         | 458/7979 [01:30<25:54,  4.84it/s]\u001b[A\n",
            "  6%|▌         | 459/7979 [01:30<26:10,  4.79it/s]\u001b[A\n",
            "  6%|▌         | 460/7979 [01:30<25:42,  4.88it/s]\u001b[A\n",
            "  6%|▌         | 461/7979 [01:31<24:57,  5.02it/s]\u001b[A\n",
            "  6%|▌         | 462/7979 [01:31<26:11,  4.78it/s]\u001b[A\n",
            "  6%|▌         | 463/7979 [01:31<25:44,  4.87it/s]\u001b[A\n",
            "  6%|▌         | 464/7979 [01:31<25:41,  4.87it/s]\u001b[A\n",
            "  6%|▌         | 465/7979 [01:31<25:07,  4.99it/s]\u001b[A\n",
            "  6%|▌         | 466/7979 [01:32<25:06,  4.99it/s]\u001b[A\n",
            "  6%|▌         | 467/7979 [01:32<25:09,  4.98it/s]\u001b[A\n",
            "  6%|▌         | 468/7979 [01:32<25:02,  5.00it/s]\u001b[A\n",
            "  6%|▌         | 469/7979 [01:32<25:02,  5.00it/s]\u001b[A\n",
            "  6%|▌         | 470/7979 [01:32<24:37,  5.08it/s]\u001b[A\n",
            "  6%|▌         | 471/7979 [01:33<24:41,  5.07it/s]\u001b[A\n",
            "  6%|▌         | 472/7979 [01:33<24:15,  5.16it/s]\u001b[A\n",
            "  6%|▌         | 473/7979 [01:33<24:20,  5.14it/s]\u001b[A\n",
            "  6%|▌         | 474/7979 [01:33<24:32,  5.10it/s]\u001b[A\n",
            "  6%|▌         | 475/7979 [01:33<24:18,  5.15it/s]\u001b[A\n",
            "  6%|▌         | 476/7979 [01:34<24:15,  5.15it/s]\u001b[A\n",
            "  6%|▌         | 477/7979 [01:34<24:24,  5.12it/s]\u001b[A\n",
            "  6%|▌         | 478/7979 [01:34<24:12,  5.16it/s]\u001b[A\n",
            "  6%|▌         | 479/7979 [01:34<24:14,  5.16it/s]\u001b[A\n",
            "  6%|▌         | 480/7979 [01:34<24:42,  5.06it/s]\u001b[A\n",
            "  6%|▌         | 481/7979 [01:35<24:25,  5.12it/s]\u001b[A\n",
            "  6%|▌         | 482/7979 [01:35<24:42,  5.06it/s]\u001b[A\n",
            "  6%|▌         | 483/7979 [01:35<24:45,  5.05it/s]\u001b[A\n",
            "  6%|▌         | 484/7979 [01:35<24:25,  5.12it/s]\u001b[A\n",
            "  6%|▌         | 485/7979 [01:35<24:12,  5.16it/s]\u001b[A\n",
            "  6%|▌         | 486/7979 [01:35<24:15,  5.15it/s]\u001b[A\n",
            "  6%|▌         | 487/7979 [01:36<23:58,  5.21it/s]\u001b[A\n",
            "  6%|▌         | 488/7979 [01:36<24:08,  5.17it/s]\u001b[A\n",
            "  6%|▌         | 489/7979 [01:36<24:16,  5.14it/s]\u001b[A\n",
            "  6%|▌         | 490/7979 [01:36<25:18,  4.93it/s]\u001b[A\n",
            "  6%|▌         | 491/7979 [01:36<24:47,  5.03it/s]\u001b[A\n",
            "  6%|▌         | 492/7979 [01:37<24:27,  5.10it/s]\u001b[A\n",
            "  6%|▌         | 493/7979 [01:37<24:31,  5.09it/s]\u001b[A\n",
            "  6%|▌         | 494/7979 [01:37<24:43,  5.05it/s]\u001b[A\n",
            "  6%|▌         | 495/7979 [01:37<24:31,  5.09it/s]\u001b[A\n",
            "  6%|▌         | 496/7979 [01:37<24:45,  5.04it/s]\u001b[A\n",
            "  6%|▌         | 497/7979 [01:38<25:42,  4.85it/s]\u001b[A\n",
            "  6%|▌         | 498/7979 [01:38<25:11,  4.95it/s]\u001b[A\n",
            "  6%|▋         | 499/7979 [01:38<24:49,  5.02it/s]\u001b[A\n",
            "  6%|▋         | 500/7979 [01:38<24:30,  5.09it/s]\u001b[A\n",
            "  6%|▋         | 501/7979 [01:38<24:20,  5.12it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.0667152926325798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  6%|▋         | 502/7979 [01:39<24:12,  5.15it/s]\u001b[A\n",
            "  6%|▋         | 503/7979 [01:39<24:08,  5.16it/s]\u001b[A\n",
            "  6%|▋         | 504/7979 [01:39<24:19,  5.12it/s]\u001b[A\n",
            "  6%|▋         | 505/7979 [01:39<23:57,  5.20it/s]\u001b[A\n",
            "  6%|▋         | 506/7979 [01:39<24:17,  5.13it/s]\u001b[A\n",
            "  6%|▋         | 507/7979 [01:40<24:26,  5.10it/s]\u001b[A\n",
            "  6%|▋         | 508/7979 [01:40<24:19,  5.12it/s]\u001b[A\n",
            "  6%|▋         | 509/7979 [01:40<24:59,  4.98it/s]\u001b[A\n",
            "  6%|▋         | 510/7979 [01:40<24:28,  5.08it/s]\u001b[A\n",
            "  6%|▋         | 511/7979 [01:40<24:22,  5.11it/s]\u001b[A\n",
            "  6%|▋         | 512/7979 [01:41<24:38,  5.05it/s]\u001b[A\n",
            "  6%|▋         | 513/7979 [01:41<25:02,  4.97it/s]\u001b[A\n",
            "  6%|▋         | 514/7979 [01:41<24:43,  5.03it/s]\u001b[A\n",
            "  6%|▋         | 515/7979 [01:41<24:56,  4.99it/s]\u001b[A\n",
            "  6%|▋         | 516/7979 [01:41<24:38,  5.05it/s]\u001b[A\n",
            "  6%|▋         | 517/7979 [01:42<24:42,  5.03it/s]\u001b[A\n",
            "  6%|▋         | 518/7979 [01:42<24:26,  5.09it/s]\u001b[A\n",
            "  7%|▋         | 519/7979 [01:42<24:57,  4.98it/s]\u001b[A\n",
            "  7%|▋         | 520/7979 [01:42<25:11,  4.94it/s]\u001b[A\n",
            "  7%|▋         | 521/7979 [01:42<24:51,  5.00it/s]\u001b[A\n",
            "  7%|▋         | 522/7979 [01:43<24:38,  5.04it/s]\u001b[A\n",
            "  7%|▋         | 523/7979 [01:43<24:28,  5.08it/s]\u001b[A\n",
            "  7%|▋         | 524/7979 [01:43<24:24,  5.09it/s]\u001b[A\n",
            "  7%|▋         | 525/7979 [01:43<24:32,  5.06it/s]\u001b[A\n",
            "  7%|▋         | 526/7979 [01:43<24:31,  5.06it/s]\u001b[A\n",
            "  7%|▋         | 527/7979 [01:44<24:18,  5.11it/s]\u001b[A\n",
            "  7%|▋         | 528/7979 [01:44<24:17,  5.11it/s]\u001b[A\n",
            "  7%|▋         | 529/7979 [01:44<24:01,  5.17it/s]\u001b[A\n",
            "  7%|▋         | 530/7979 [01:44<24:27,  5.08it/s]\u001b[A\n",
            "  7%|▋         | 531/7979 [01:44<25:25,  4.88it/s]\u001b[A\n",
            "  7%|▋         | 532/7979 [01:45<25:52,  4.80it/s]\u001b[A\n",
            "  7%|▋         | 533/7979 [01:45<25:14,  4.92it/s]\u001b[A\n",
            "  7%|▋         | 534/7979 [01:45<25:22,  4.89it/s]\u001b[A\n",
            "  7%|▋         | 535/7979 [01:45<25:51,  4.80it/s]\u001b[A\n",
            "  7%|▋         | 536/7979 [01:45<25:00,  4.96it/s]\u001b[A\n",
            "  7%|▋         | 537/7979 [01:46<24:45,  5.01it/s]\u001b[A\n",
            "  7%|▋         | 538/7979 [01:46<25:06,  4.94it/s]\u001b[A\n",
            "  7%|▋         | 539/7979 [01:46<25:42,  4.82it/s]\u001b[A\n",
            "  7%|▋         | 540/7979 [01:46<26:10,  4.74it/s]\u001b[A\n",
            "  7%|▋         | 541/7979 [01:46<25:37,  4.84it/s]\u001b[A\n",
            "  7%|▋         | 542/7979 [01:47<26:05,  4.75it/s]\u001b[A\n",
            "  7%|▋         | 543/7979 [01:47<25:15,  4.91it/s]\u001b[A\n",
            "  7%|▋         | 544/7979 [01:47<25:12,  4.92it/s]\u001b[A\n",
            "  7%|▋         | 545/7979 [01:47<24:52,  4.98it/s]\u001b[A\n",
            "  7%|▋         | 546/7979 [01:47<25:06,  4.94it/s]\u001b[A\n",
            "  7%|▋         | 547/7979 [01:48<24:40,  5.02it/s]\u001b[A\n",
            "  7%|▋         | 548/7979 [01:48<24:22,  5.08it/s]\u001b[A\n",
            "  7%|▋         | 549/7979 [01:48<24:45,  5.00it/s]\u001b[A\n",
            "  7%|▋         | 550/7979 [01:48<24:39,  5.02it/s]\u001b[A\n",
            "  7%|▋         | 551/7979 [01:48<24:36,  5.03it/s]\u001b[A\n",
            "  7%|▋         | 552/7979 [01:49<24:14,  5.11it/s]\u001b[A\n",
            "  7%|▋         | 553/7979 [01:49<23:57,  5.17it/s]\u001b[A\n",
            "  7%|▋         | 554/7979 [01:49<23:51,  5.19it/s]\u001b[A\n",
            "  7%|▋         | 555/7979 [01:49<23:59,  5.16it/s]\u001b[A\n",
            "  7%|▋         | 556/7979 [01:49<24:12,  5.11it/s]\u001b[A\n",
            "  7%|▋         | 557/7979 [01:50<24:04,  5.14it/s]\u001b[A\n",
            "  7%|▋         | 558/7979 [01:50<24:36,  5.03it/s]\u001b[A\n",
            "  7%|▋         | 559/7979 [01:50<24:43,  5.00it/s]\u001b[A\n",
            "  7%|▋         | 560/7979 [01:50<24:41,  5.01it/s]\u001b[A\n",
            "  7%|▋         | 561/7979 [01:50<24:20,  5.08it/s]\u001b[A\n",
            "  7%|▋         | 562/7979 [01:51<24:02,  5.14it/s]\u001b[A\n",
            "  7%|▋         | 563/7979 [01:51<24:33,  5.03it/s]\u001b[A\n",
            "  7%|▋         | 564/7979 [01:51<25:05,  4.93it/s]\u001b[A\n",
            "  7%|▋         | 565/7979 [01:51<24:43,  5.00it/s]\u001b[A\n",
            "  7%|▋         | 566/7979 [01:51<25:26,  4.86it/s]\u001b[A\n",
            "  7%|▋         | 567/7979 [01:52<25:12,  4.90it/s]\u001b[A\n",
            "  7%|▋         | 568/7979 [01:52<25:15,  4.89it/s]\u001b[A\n",
            "  7%|▋         | 569/7979 [01:52<25:30,  4.84it/s]\u001b[A\n",
            "  7%|▋         | 570/7979 [01:52<25:09,  4.91it/s]\u001b[A\n",
            "  7%|▋         | 571/7979 [01:52<24:59,  4.94it/s]\u001b[A\n",
            "  7%|▋         | 572/7979 [01:53<24:21,  5.07it/s]\u001b[A\n",
            "  7%|▋         | 573/7979 [01:53<24:16,  5.09it/s]\u001b[A\n",
            "  7%|▋         | 574/7979 [01:53<24:09,  5.11it/s]\u001b[A\n",
            "  7%|▋         | 575/7979 [01:53<24:50,  4.97it/s]\u001b[A\n",
            "  7%|▋         | 576/7979 [01:53<24:44,  4.99it/s]\u001b[A\n",
            "  7%|▋         | 577/7979 [01:54<24:54,  4.95it/s]\u001b[A\n",
            "  7%|▋         | 578/7979 [01:54<25:02,  4.93it/s]\u001b[A\n",
            "  7%|▋         | 579/7979 [01:54<25:02,  4.93it/s]\u001b[A\n",
            "  7%|▋         | 580/7979 [01:54<25:09,  4.90it/s]\u001b[A\n",
            "  7%|▋         | 581/7979 [01:54<24:38,  5.00it/s]\u001b[A\n",
            "  7%|▋         | 582/7979 [01:55<24:11,  5.09it/s]\u001b[A\n",
            "  7%|▋         | 583/7979 [01:55<24:10,  5.10it/s]\u001b[A\n",
            "  7%|▋         | 584/7979 [01:55<24:08,  5.10it/s]\u001b[A\n",
            "  7%|▋         | 585/7979 [01:55<23:52,  5.16it/s]\u001b[A\n",
            "  7%|▋         | 586/7979 [01:55<23:52,  5.16it/s]\u001b[A\n",
            "  7%|▋         | 587/7979 [01:56<24:13,  5.09it/s]\u001b[A\n",
            "  7%|▋         | 588/7979 [01:56<24:02,  5.12it/s]\u001b[A\n",
            "  7%|▋         | 589/7979 [01:56<24:29,  5.03it/s]\u001b[A\n",
            "  7%|▋         | 590/7979 [01:56<24:48,  4.96it/s]\u001b[A\n",
            "  7%|▋         | 591/7979 [01:56<25:01,  4.92it/s]\u001b[A\n",
            "  7%|▋         | 592/7979 [01:57<25:20,  4.86it/s]\u001b[A\n",
            "  7%|▋         | 593/7979 [01:57<24:51,  4.95it/s]\u001b[A\n",
            "  7%|▋         | 594/7979 [01:57<24:24,  5.04it/s]\u001b[A\n",
            "  7%|▋         | 595/7979 [01:57<24:30,  5.02it/s]\u001b[A\n",
            "  7%|▋         | 596/7979 [01:57<24:09,  5.09it/s]\u001b[A\n",
            "  7%|▋         | 597/7979 [01:58<24:58,  4.93it/s]\u001b[A\n",
            "  7%|▋         | 598/7979 [01:58<24:50,  4.95it/s]\u001b[A\n",
            "  8%|▊         | 599/7979 [01:58<24:25,  5.04it/s]\u001b[A\n",
            "  8%|▊         | 600/7979 [01:58<24:01,  5.12it/s]\u001b[A\n",
            "  8%|▊         | 601/7979 [01:58<23:53,  5.15it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.08836552500724792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  8%|▊         | 602/7979 [01:59<23:52,  5.15it/s]\u001b[A\n",
            "  8%|▊         | 603/7979 [01:59<24:31,  5.01it/s]\u001b[A\n",
            "  8%|▊         | 604/7979 [01:59<24:34,  5.00it/s]\u001b[A\n",
            "  8%|▊         | 605/7979 [01:59<24:20,  5.05it/s]\u001b[A\n",
            "  8%|▊         | 606/7979 [01:59<24:10,  5.08it/s]\u001b[A\n",
            "  8%|▊         | 607/7979 [02:00<24:44,  4.97it/s]\u001b[A\n",
            "  8%|▊         | 608/7979 [02:00<24:27,  5.02it/s]\u001b[A\n",
            "  8%|▊         | 609/7979 [02:00<24:11,  5.08it/s]\u001b[A\n",
            "  8%|▊         | 610/7979 [02:00<23:37,  5.20it/s]\u001b[A\n",
            "  8%|▊         | 611/7979 [02:00<23:38,  5.20it/s]\u001b[A\n",
            "  8%|▊         | 612/7979 [02:01<23:53,  5.14it/s]\u001b[A\n",
            "  8%|▊         | 613/7979 [02:01<23:37,  5.20it/s]\u001b[A\n",
            "  8%|▊         | 614/7979 [02:01<24:30,  5.01it/s]\u001b[A\n",
            "  8%|▊         | 615/7979 [02:01<24:38,  4.98it/s]\u001b[A\n",
            "  8%|▊         | 616/7979 [02:01<24:20,  5.04it/s]\u001b[A\n",
            "  8%|▊         | 617/7979 [02:02<25:10,  4.87it/s]\u001b[A\n",
            "  8%|▊         | 618/7979 [02:02<25:29,  4.81it/s]\u001b[A\n",
            "  8%|▊         | 619/7979 [02:02<24:49,  4.94it/s]\u001b[A\n",
            "  8%|▊         | 620/7979 [02:02<24:36,  4.98it/s]\u001b[A\n",
            "  8%|▊         | 621/7979 [02:02<24:10,  5.07it/s]\u001b[A\n",
            "  8%|▊         | 622/7979 [02:03<24:47,  4.95it/s]\u001b[A\n",
            "  8%|▊         | 623/7979 [02:03<24:11,  5.07it/s]\u001b[A\n",
            "  8%|▊         | 624/7979 [02:03<24:13,  5.06it/s]\u001b[A\n",
            "  8%|▊         | 625/7979 [02:03<24:10,  5.07it/s]\u001b[A\n",
            "  8%|▊         | 626/7979 [02:03<24:00,  5.10it/s]\u001b[A\n",
            "  8%|▊         | 627/7979 [02:04<24:00,  5.10it/s]\u001b[A\n",
            "  8%|▊         | 628/7979 [02:04<23:57,  5.12it/s]\u001b[A\n",
            "  8%|▊         | 629/7979 [02:04<23:30,  5.21it/s]\u001b[A\n",
            "  8%|▊         | 630/7979 [02:04<23:39,  5.18it/s]\u001b[A\n",
            "  8%|▊         | 631/7979 [02:04<23:33,  5.20it/s]\u001b[A\n",
            "  8%|▊         | 632/7979 [02:05<23:32,  5.20it/s]\u001b[A\n",
            "  8%|▊         | 633/7979 [02:05<23:30,  5.21it/s]\u001b[A\n",
            "  8%|▊         | 634/7979 [02:05<24:10,  5.06it/s]\u001b[A\n",
            "  8%|▊         | 635/7979 [02:05<23:53,  5.12it/s]\u001b[A\n",
            "  8%|▊         | 636/7979 [02:05<23:52,  5.13it/s]\u001b[A\n",
            "  8%|▊         | 637/7979 [02:05<23:44,  5.15it/s]\u001b[A\n",
            "  8%|▊         | 638/7979 [02:06<24:17,  5.04it/s]\u001b[A\n",
            "  8%|▊         | 639/7979 [02:06<24:11,  5.06it/s]\u001b[A\n",
            "  8%|▊         | 640/7979 [02:06<24:06,  5.07it/s]\u001b[A\n",
            "  8%|▊         | 641/7979 [02:06<23:49,  5.13it/s]\u001b[A\n",
            "  8%|▊         | 642/7979 [02:07<24:34,  4.97it/s]\u001b[A\n",
            "  8%|▊         | 643/7979 [02:07<24:46,  4.94it/s]\u001b[A\n",
            "  8%|▊         | 644/7979 [02:07<24:56,  4.90it/s]\u001b[A\n",
            "  8%|▊         | 645/7979 [02:07<24:32,  4.98it/s]\u001b[A\n",
            "  8%|▊         | 646/7979 [02:07<24:10,  5.06it/s]\u001b[A\n",
            "  8%|▊         | 647/7979 [02:07<23:56,  5.10it/s]\u001b[A\n",
            "  8%|▊         | 648/7979 [02:08<24:01,  5.08it/s]\u001b[A\n",
            "  8%|▊         | 649/7979 [02:08<23:38,  5.17it/s]\u001b[A\n",
            "  8%|▊         | 650/7979 [02:08<23:36,  5.17it/s]\u001b[A\n",
            "  8%|▊         | 651/7979 [02:08<23:23,  5.22it/s]\u001b[A\n",
            "  8%|▊         | 652/7979 [02:08<23:18,  5.24it/s]\u001b[A\n",
            "  8%|▊         | 653/7979 [02:09<23:12,  5.26it/s]\u001b[A\n",
            "  8%|▊         | 654/7979 [02:09<23:21,  5.23it/s]\u001b[A\n",
            "  8%|▊         | 655/7979 [02:09<23:36,  5.17it/s]\u001b[A\n",
            "  8%|▊         | 656/7979 [02:09<23:43,  5.14it/s]\u001b[A\n",
            "  8%|▊         | 657/7979 [02:09<23:57,  5.09it/s]\u001b[A\n",
            "  8%|▊         | 658/7979 [02:10<24:20,  5.01it/s]\u001b[A\n",
            "  8%|▊         | 659/7979 [02:10<24:19,  5.02it/s]\u001b[A\n",
            "  8%|▊         | 660/7979 [02:10<24:30,  4.98it/s]\u001b[A\n",
            "  8%|▊         | 661/7979 [02:10<24:27,  4.99it/s]\u001b[A\n",
            "  8%|▊         | 662/7979 [02:10<24:10,  5.04it/s]\u001b[A\n",
            "  8%|▊         | 663/7979 [02:11<24:34,  4.96it/s]\u001b[A\n",
            "  8%|▊         | 664/7979 [02:11<25:03,  4.87it/s]\u001b[A\n",
            "  8%|▊         | 665/7979 [02:11<24:45,  4.92it/s]\u001b[A\n",
            "  8%|▊         | 666/7979 [02:11<24:17,  5.02it/s]\u001b[A\n",
            "  8%|▊         | 667/7979 [02:11<24:50,  4.91it/s]\u001b[A\n",
            "  8%|▊         | 668/7979 [02:12<24:25,  4.99it/s]\u001b[A\n",
            "  8%|▊         | 669/7979 [02:12<24:39,  4.94it/s]\u001b[A\n",
            "  8%|▊         | 670/7979 [02:12<24:05,  5.06it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c6928e977afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-278d854573f6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mepoch_step\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58vueodjzKDt",
        "colab_type": "text"
      },
      "source": [
        "<a id='section06'></a>\n",
        "### Validating the Model\n",
        "\n",
        "During the validation stage we pass the unseen data(Testing Dataset) to the model. This step determines how good the model performs on the unseen data. \n",
        "\n",
        "This unseen data is the 20% of `train.csv` which was seperated during the Dataset creation stage. \n",
        "During the validation stage the weights of the model are not updated. Only the final output is compared to the actual value. This comparison is then used to calcuate the accuracy of the model. \n",
        "\n",
        "As defined above to get a measure of our models performance we are using the following metrics. \n",
        "- Accuracy Score\n",
        "- F1 Micro\n",
        "- F1 Macro\n",
        "\n",
        "We are getting amazing results for all these 3 categories just by training the model for 1 Epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nIEoUm4aQkyl",
        "colab": {}
      },
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ov1_3R_pAcMo",
        "outputId": "0d9eca6e-624a-48f6-b7c7-be1a47b28247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    outputs, targets = validation(epoch)\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score = 0.9214451337970796\n",
            "F1 Score (Micro) = 0.7240212663122282\n",
            "F1 Score (Macro) = 0.4037705040668253\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}